{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import shap\n",
    "from xgboost import XGBClassifier\n",
    "# import random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#import linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# import tqdm\n",
    "from tqdm import tqdm\n",
    "import tqdm\n",
    "#import r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "#import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import roc auc score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from food_crisis_functions import *\n",
    "import json\n",
    "with open(\"forecasting_hyperparameters.json\", \"r\") as file:\n",
    "    best_params_xgb_regressor= json.load(file)\n",
    "    \n",
    "with open(\"forecasting_hyperparameters_p3.json\", \"r\") as file:\n",
    "    best_params_xgb_regressor_for_p3= json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# read csv\n",
    "df = pd.read_csv(r'C:\\Users\\swl00\\IFPRI Dropbox\\Weilun Shi\\Google fund\\Analysis\\1.Source Data\\forecasting_subset_IPCCH_v1210.csv')\n",
    "# add dummys for area_id and month year\n",
    "#df = pd.concat([df, pd.get_dummies(df['area_id'], prefix='area_id')], axis=1)\n",
    "#df = pd.concat([df, pd.get_dummies(df['date'], prefix='month_year')], axis=1)\n",
    "# drop lat and lon\n",
    "#df = df.drop(['lat', 'lon'], axis=1)\n",
    "###drop fews_ipc_ha\n",
    "#df = df.drop(['fews_ipc_ha'], axis=1)\n",
    "# random split train and test\n",
    "\n",
    "# prepare date from year and month\n",
    "df['date'] = pd.to_datetime(df[['year', 'month']].assign(DAY=1))\n",
    "# check for inf and replace with na\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# replace df['overall_phase], 0 as 1, >5 as 5\n",
    "df['overall_phase'] = df['overall_phase'].apply(lambda x: 1 if x < 1 else (5 if x > 5 else x))\n",
    "\n",
    "df_origin = df.copy()\n",
    "y_pred_test = pd.DataFrame()\n",
    "model_stats = pd.DataFrame()\n",
    "#select phase1_percent is not na\n",
    "df = df_origin[df_origin['phase1_percent'].notna()]\n",
    "\n",
    "# Sort by region and date\n",
    "df = df.sort_values(by=['area_id', 'date'])\n",
    "#drop overall phase\n",
    "df = df.drop(['overall_phase'], axis=1)\n",
    "#for each region, set last observation to be test set\n",
    "# create a series of new outcome, phase2_worse=phase2_percent+phase3_percent+phase4_percent+phase5_percent, phase3_worse=phase3_percent+phase4_percent+phase5_percent, phase4_worse=phase4_percent+phase5_percent, phase5_worse=phase5_percent\n",
    "df['phase2_worse'] = df['phase2_percent'] + df['phase3_percent'] + df['phase4_percent'] + df['phase5_percent']\n",
    "df['phase3_worse'] = df['phase3_percent'] + df['phase4_percent'] + df['phase5_percent']\n",
    "df['phase4_worse'] = df['phase4_percent'] + df['phase5_percent']\n",
    "df['phase5_worse'] = df['phase5_percent']\n",
    "#drop phase2_percent, phase3_percent, phase4_percent, phase5_percent, phase1_percent\n",
    "df = df.drop(['phase2_percent', 'phase3_percent', 'phase4_percent', 'phase5_percent', 'phase1_percent'], axis=1)\n",
    "# Splitting the data\n",
    "#test_df = df.groupby('area_id').tail(1)\n",
    "#train_df = df.drop(test_df.index)\n",
    "#test_df = test_df.drop(['area_id','date'], axis=1)\n",
    "#train_df = train_df.drop(['area_id','date'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.to_csv(r'C:\\Users\\swl00\\IFPRI Dropbox\\Weilun Shi\\Google fund\\Analysis\\1.Source Data\\forecasting_subset_IPCCH_v1210_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6614668218859139\n",
      "Sensitivity: 0.8358045030203185\n",
      "Precision: 0.7213270142180095\n",
      "Overall R²(Phase 3 or more): 0.44595340390635263\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred_test = pd.DataFrame()\n",
    "# drop anything after 2022-01-01\n",
    "#df = df[df['date'] < '2021-01-01']\n",
    "shape_values_df_ensemble = pd.DataFrame()\n",
    "df_result = pd.DataFrame()\n",
    "date = \"2024-01-01\"  # Define the 'date' variable\n",
    "train_start_date = \"2021-01-01\"\n",
    "#order unique_dates\n",
    "y_pred_test=pd.DataFrame()\n",
    "\n",
    "for i in range(2, 6):\n",
    "    train_df = df[(df['date'] >= train_start_date) & (df['date'] < date)]\n",
    "    test_df = df[df['date'] >= date]\n",
    "    train_df = train_df.drop(['date','area_id'], axis=1)\n",
    "    test_df = test_df.drop(['date','area_id'], axis=1)\n",
    "    train_df_new = train_df.drop(['phase{}_worse'.format(j) for j in range(2, 6) if j != i], axis=1)\n",
    "    test_df_new = test_df.drop(['phase{}_worse'.format(j) for j in range(2, 6) if j != i], axis=1)\n",
    "# drop rows with NaN in phase{}_percent\n",
    "    train_df_new = train_df_new.dropna(subset=['phase{}_worse'.format(i)])\n",
    "    test_df_new = test_df_new.dropna(subset=['phase{}_worse'.format(i)])\n",
    "    test_index = test_df_new.index\n",
    "    # Split into features and target\n",
    "    X_train = train_df_new.drop('phase{}_worse'.format(i), axis=1)\n",
    "    y_train = train_df_new['phase{}_worse'.format(i)]\n",
    "    X_test = test_df_new.drop('phase{}_worse'.format(i), axis=1)\n",
    "    y_test = test_df_new['phase{}_worse'.format(i)]\n",
    "    #fews_ipc_ha_test = X_test['fews_ipc_ha']\n",
    "    #X_train = X_train.drop(['fews_ipc_ha'], axis=1)\n",
    "    #X_test = X_test.drop(['fews_ipc_ha'], axis=1)\n",
    "    if i == 3:\n",
    "        best_params_xgb_regressor = best_params_xgb_regressor_for_p3\n",
    "    model = xgb.XGBRegressor(**best_params_xgb_regressor)\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    # for y_pred_test, add a column to indicate the phase\n",
    "    #y_pred_test = pd.concat([y_pred_test, pd.DataFrame({'y_pred': y_pred, 'y_test': y_test, 'phase': [i]*len(y_pred),'fews_ipc_ha':fews_ipc_ha_test,'test_index':test_index})], ignore_index=True)\n",
    "    if i != 5:\n",
    "        y_pred_test = pd.concat([y_pred_test, pd.DataFrame({'y_pred': y_pred, 'y_test': y_test, 'phase': [i]*len(y_pred)})], ignore_index=True)\n",
    "    else:\n",
    "        y_pred_test = pd.concat([y_pred_test, pd.DataFrame({'y_pred': y_pred, 'y_test': y_test, 'phase': [i]*len(y_pred),'test_index':test_index})], ignore_index=True)\n",
    "   \n",
    "    # shap values\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    \n",
    "    #save shap values\n",
    "    shap_values_df = pd.DataFrame(shap_values, columns=X_train.columns)\n",
    "    \n",
    "    # add a column to indicate the phase\n",
    "    shap_values_df['phase'] = i\n",
    "    \n",
    "    # append to shape_values_df_ensemble\n",
    "    shape_values_df_ensemble = pd.concat([shape_values_df_ensemble, shap_values_df], ignore_index=True)\n",
    "y_pred_test = convert_prob_to_phase(y_pred_test)\n",
    "y_test = y_pred_test['overall_phase']\n",
    "y_pred = y_pred_test['overall_phase_pred']\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "accuracy_score_new, sensitivity, precision, overall_r2 = all_metrics(y_test, y_pred, cm, y_pred_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score_new)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Overall R²(Phase 3 or more):\", overall_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save y_pred_test to csv (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swl00\\AppData\\Local\\Temp\\ipykernel_31420\\609577449.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extracted['test_index'] = df_extracted.index\n"
     ]
    }
   ],
   "source": [
    "# remove column if it is all 0\n",
    "y_pred_test = y_pred_test.loc[:, (y_pred_test != 0).any(axis=0)]\n",
    "#extract df area_id, date\n",
    "df_extracted = df[['area_id', 'date']]\n",
    "\n",
    "# generate index\n",
    "df_extracted['test_index'] = df_extracted.index\n",
    "\n",
    "# merge y_pred_test with df_extracted on test_index\n",
    "y_pred_test = y_pred_test.merge(df_extracted, on='test_index', how='left')\n",
    "#read IPCCH\n",
    "PATH = r'C:\\Users\\swl00\\IFPRI Dropbox\\Weilun Shi\\Google fund\\Analysis\\1.Source Data\\IPCCH_2017_2025_final_v12102025_with_zscores.csv'\n",
    "df_ipcch = pd.read_csv(PATH)\n",
    "# keep only admin_code, lat, lon\n",
    "df_ipcch = df_ipcch[['admin_code', 'lat', 'lon']]\n",
    "\n",
    "# rename admin_code to area_id\n",
    "df_ipcch = df_ipcch.rename(columns={'admin_code': 'area_id'})\n",
    "\n",
    "# merge y_pred_test with df_ipcch on area_id\n",
    "y_pred_test = y_pred_test.merge(df_ipcch, on='area_id', how='left')\n",
    "# save y_pred_test to csv\n",
    "y_pred_test.to_csv(r'C:\\Users\\swl00\\IFPRI Dropbox\\Weilun Shi\\Google fund\\Analysis\\2.source_code\\Step5_Geo_RF_trial\\IPCCH_model\\forecasting_prediction\\forecasting_y_pred_test_2024.csv', index=False)\n",
    "# clean all memory\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import shap\n",
    "from xgboost import XGBClassifier\n",
    "# import random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#import linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# import tqdm\n",
    "from tqdm import tqdm\n",
    "import tqdm\n",
    "#import r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "#import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import roc auc score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from food_crisis_functions import *\n",
    "import json\n",
    "with open(\"forecasting_hyperparameters.json\", \"r\") as file:\n",
    "    best_params_xgb_regressor= json.load(file)\n",
    "    \n",
    "with open(\"forecasting_hyperparameters_p3.json\", \"r\") as file:\n",
    "    best_params_xgb_regressor_for_p3= json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6111675126903553\n",
      "Sensitivity: 0.8882952889752307\n",
      "Precision: 0.7398867313915858\n",
      "Overall R²(Phase 3 or more): 0.5509501799216117\n"
     ]
    }
   ],
   "source": [
    "# read csv\n",
    "df = pd.read_csv(r'C:\\Users\\swl00\\IFPRI Dropbox\\Weilun Shi\\Google fund\\Analysis\\1.Source Data\\forecasting_subset_IPCCH_v1210.csv')\n",
    "# add dummys for area_id and month year\n",
    "#df = pd.concat([df, pd.get_dummies(df['area_id'], prefix='area_id')], axis=1)\n",
    "#df = pd.concat([df, pd.get_dummies(df['date'], prefix='month_year')], axis=1)\n",
    "# drop lat and lon\n",
    "#df = df.drop(['lat', 'lon'], axis=1)\n",
    "###drop fews_ipc_ha\n",
    "#df = df.drop(['fews_ipc_ha'], axis=1)\n",
    "# random split train and test\n",
    "\n",
    "# prepare date from year and month\n",
    "df['date'] = pd.to_datetime(df[['year', 'month']].assign(DAY=1))\n",
    "# check for inf and replace with na\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# replace df['overall_phase], 0 as 1, >5 as 5\n",
    "df['overall_phase'] = df['overall_phase'].apply(lambda x: 1 if x < 1 else (5 if x > 5 else x))\n",
    "\n",
    "df_origin = df.copy()\n",
    "y_pred_test = pd.DataFrame()\n",
    "model_stats = pd.DataFrame()\n",
    "#select phase1_percent is not na\n",
    "df = df_origin[df_origin['phase1_percent'].notna()]\n",
    "\n",
    "# Sort by region and date\n",
    "df = df.sort_values(by=['area_id', 'date'])\n",
    "#drop overall phase\n",
    "df = df.drop(['overall_phase'], axis=1)\n",
    "#for each region, set last observation to be test set\n",
    "# create a series of new outcome, phase2_worse=phase2_percent+phase3_percent+phase4_percent+phase5_percent, phase3_worse=phase3_percent+phase4_percent+phase5_percent, phase4_worse=phase4_percent+phase5_percent, phase5_worse=phase5_percent\n",
    "df['phase2_worse'] = df['phase2_percent'] + df['phase3_percent'] + df['phase4_percent'] + df['phase5_percent']\n",
    "df['phase3_worse'] = df['phase3_percent'] + df['phase4_percent'] + df['phase5_percent']\n",
    "df['phase4_worse'] = df['phase4_percent'] + df['phase5_percent']\n",
    "df['phase5_worse'] = df['phase5_percent']\n",
    "#drop phase2_percent, phase3_percent, phase4_percent, phase5_percent, phase1_percent\n",
    "df = df.drop(['phase2_percent', 'phase3_percent', 'phase4_percent', 'phase5_percent', 'phase1_percent'], axis=1)\n",
    "# Splitting the data\n",
    "#test_df = df.groupby('area_id').tail(1)\n",
    "#train_df = df.drop(test_df.index)\n",
    "#test_df = test_df.drop(['area_id','date'], axis=1)\n",
    "#train_df = train_df.drop(['area_id','date'], axis=1)\n",
    "y_pred_test = pd.DataFrame()\n",
    "# drop anything after 2022-01-01\n",
    "#df = df[df['date'] < '2021-01-01']\n",
    "shape_values_df_ensemble = pd.DataFrame()\n",
    "df_result = pd.DataFrame()\n",
    "date = \"2023-01-01\"  # Define the 'date' variable\n",
    "train_start_date = \"2020-01-01\"\n",
    "cutoff_date = \"2024-01-01\"\n",
    "#order unique_dates\n",
    "y_pred_test=pd.DataFrame()\n",
    "\n",
    "for i in range(2, 6):\n",
    "    train_df = df[(df['date'] >= train_start_date) & (df['date'] < date)]\n",
    "    test_df = df[(df['date'] < cutoff_date) & (df['date'] >= date)]\n",
    "    train_df = train_df.drop(['date','area_id'], axis=1)\n",
    "    test_df = test_df.drop(['date','area_id'], axis=1)\n",
    "    train_df_new = train_df.drop(['phase{}_worse'.format(j) for j in range(2, 6) if j != i], axis=1)\n",
    "    test_df_new = test_df.drop(['phase{}_worse'.format(j) for j in range(2, 6) if j != i], axis=1)\n",
    "# drop rows with NaN in phase{}_percent\n",
    "    train_df_new = train_df_new.dropna(subset=['phase{}_worse'.format(i)])\n",
    "    test_df_new = test_df_new.dropna(subset=['phase{}_worse'.format(i)])\n",
    "    test_index = test_df_new.index\n",
    "    # Split into features and target\n",
    "    X_train = train_df_new.drop('phase{}_worse'.format(i), axis=1)\n",
    "    y_train = train_df_new['phase{}_worse'.format(i)]\n",
    "    X_test = test_df_new.drop('phase{}_worse'.format(i), axis=1)\n",
    "    y_test = test_df_new['phase{}_worse'.format(i)]\n",
    "    #fews_ipc_ha_test = X_test['fews_ipc_ha']\n",
    "    #X_train = X_train.drop(['fews_ipc_ha'], axis=1)\n",
    "    #X_test = X_test.drop(['fews_ipc_ha'], axis=1)\n",
    "    if i == 3:\n",
    "        best_params_xgb_regressor = best_params_xgb_regressor_for_p3\n",
    "    model = xgb.XGBRegressor(**best_params_xgb_regressor)\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    # for y_pred_test, add a column to indicate the phase\n",
    "    #y_pred_test = pd.concat([y_pred_test, pd.DataFrame({'y_pred': y_pred, 'y_test': y_test, 'phase': [i]*len(y_pred),'fews_ipc_ha':fews_ipc_ha_test,'test_index':test_index})], ignore_index=True)\n",
    "    if i != 5:\n",
    "        y_pred_test = pd.concat([y_pred_test, pd.DataFrame({'y_pred': y_pred, 'y_test': y_test, 'phase': [i]*len(y_pred)})], ignore_index=True)\n",
    "    else:\n",
    "        y_pred_test = pd.concat([y_pred_test, pd.DataFrame({'y_pred': y_pred, 'y_test': y_test, 'phase': [i]*len(y_pred),'test_index':test_index})], ignore_index=True)\n",
    "    # shap values\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    \n",
    "    #save shap values\n",
    "    shap_values_df = pd.DataFrame(shap_values, columns=X_train.columns)\n",
    "    \n",
    "    # add a column to indicate the phase\n",
    "    shap_values_df['phase'] = i\n",
    "    \n",
    "    # append to shape_values_df_ensemble\n",
    "    shape_values_df_ensemble = pd.concat([shape_values_df_ensemble, shap_values_df], ignore_index=True)\n",
    "y_pred_test = convert_prob_to_phase(y_pred_test)\n",
    "y_test = y_pred_test['overall_phase']\n",
    "y_pred = y_pred_test['overall_phase_pred']\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "accuracy_score_new, sensitivity, precision, overall_r2 = all_metrics(y_test, y_pred, cm, y_pred_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score_new)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Overall R²(Phase 3 or more):\", overall_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swl00\\AppData\\Local\\Temp\\ipykernel_31420\\2892231241.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extracted['test_index'] = df_extracted.index\n"
     ]
    }
   ],
   "source": [
    "# remove column if it is all 0\n",
    "y_pred_test = y_pred_test.loc[:, (y_pred_test != 0).any(axis=0)]\n",
    "#extract df area_id, date\n",
    "df_extracted = df[['area_id', 'date']]\n",
    "\n",
    "# generate index\n",
    "df_extracted['test_index'] = df_extracted.index\n",
    "\n",
    "# merge y_pred_test with df_extracted on test_index\n",
    "y_pred_test = y_pred_test.merge(df_extracted, on='test_index', how='left')\n",
    "#read IPCCH\n",
    "PATH = r'C:\\Users\\swl00\\IFPRI Dropbox\\Weilun Shi\\Google fund\\Analysis\\1.Source Data\\IPCCH_2017_2025_final_v12102025_with_zscores.csv'\n",
    "df_ipcch = pd.read_csv(PATH)\n",
    "# keep only admin_code, lat, lon\n",
    "df_ipcch = df_ipcch[['admin_code', 'lat', 'lon']]\n",
    "\n",
    "# rename admin_code to area_id\n",
    "df_ipcch = df_ipcch.rename(columns={'admin_code': 'area_id'})\n",
    "\n",
    "# merge y_pred_test with df_ipcch on area_id\n",
    "y_pred_test = y_pred_test.merge(df_ipcch, on='area_id', how='left')\n",
    "# save y_pred_test to csv\n",
    "y_pred_test.to_csv(r'C:\\Users\\swl00\\IFPRI Dropbox\\Weilun Shi\\Google fund\\Analysis\\2.source_code\\Step5_Geo_RF_trial\\IPCCH_model\\forecasting_prediction\\forecasting_y_pred_test_2023.csv', index=False)\n",
    "# clean all memory\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import shap\n",
    "from xgboost import XGBClassifier\n",
    "# import random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#import linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# import tqdm\n",
    "from tqdm import tqdm\n",
    "import tqdm\n",
    "#import r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "#import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import roc auc score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from food_crisis_functions import *\n",
    "import json\n",
    "with open(\"forecasting_hyperparameters.json\", \"r\") as file:\n",
    "    best_params_xgb_regressor= json.load(file)\n",
    "    \n",
    "with open(\"forecasting_hyperparameters_p3.json\", \"r\") as file:\n",
    "    best_params_xgb_regressor_for_p3= json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.500962927298989\n",
      "Sensitivity: 0.61714621256606\n",
      "Precision: 0.7318941504178273\n",
      "Overall R²(Phase 3 or more): 0.31057353290407996\n"
     ]
    }
   ],
   "source": [
    "# read csv\n",
    "df = pd.read_csv(r'C:\\Users\\swl00\\IFPRI Dropbox\\Weilun Shi\\Google fund\\Analysis\\1.Source Data\\forecasting_subset_IPCCH_v1210.csv')\n",
    "# add dummys for area_id and month year\n",
    "#df = pd.concat([df, pd.get_dummies(df['area_id'], prefix='area_id')], axis=1)\n",
    "#df = pd.concat([df, pd.get_dummies(df['date'], prefix='month_year')], axis=1)\n",
    "# drop lat and lon\n",
    "#df = df.drop(['lat', 'lon'], axis=1)\n",
    "###drop fews_ipc_ha\n",
    "#df = df.drop(['fews_ipc_ha'], axis=1)\n",
    "# random split train and test\n",
    "\n",
    "# prepare date from year and month\n",
    "df['date'] = pd.to_datetime(df[['year', 'month']].assign(DAY=1))\n",
    "# check for inf and replace with na\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# replace df['overall_phase], 0 as 1, >5 as 5\n",
    "df['overall_phase'] = df['overall_phase'].apply(lambda x: 1 if x < 1 else (5 if x > 5 else x))\n",
    "\n",
    "df_origin = df.copy()\n",
    "y_pred_test = pd.DataFrame()\n",
    "model_stats = pd.DataFrame()\n",
    "#select phase1_percent is not na\n",
    "df = df_origin[df_origin['phase1_percent'].notna()]\n",
    "\n",
    "# Sort by region and date\n",
    "df = df.sort_values(by=['area_id', 'date'])\n",
    "#drop overall phase\n",
    "df = df.drop(['overall_phase'], axis=1)\n",
    "#for each region, set last observation to be test set\n",
    "# create a series of new outcome, phase2_worse=phase2_percent+phase3_percent+phase4_percent+phase5_percent, phase3_worse=phase3_percent+phase4_percent+phase5_percent, phase4_worse=phase4_percent+phase5_percent, phase5_worse=phase5_percent\n",
    "df['phase2_worse'] = df['phase2_percent'] + df['phase3_percent'] + df['phase4_percent'] + df['phase5_percent']\n",
    "df['phase3_worse'] = df['phase3_percent'] + df['phase4_percent'] + df['phase5_percent']\n",
    "df['phase4_worse'] = df['phase4_percent'] + df['phase5_percent']\n",
    "df['phase5_worse'] = df['phase5_percent']\n",
    "#drop phase2_percent, phase3_percent, phase4_percent, phase5_percent, phase1_percent\n",
    "df = df.drop(['phase2_percent', 'phase3_percent', 'phase4_percent', 'phase5_percent', 'phase1_percent'], axis=1)\n",
    "# Splitting the data\n",
    "#test_df = df.groupby('area_id').tail(1)\n",
    "#train_df = df.drop(test_df.index)\n",
    "#test_df = test_df.drop(['area_id','date'], axis=1)\n",
    "#train_df = train_df.drop(['area_id','date'], axis=1)\n",
    "y_pred_test = pd.DataFrame()\n",
    "# drop anything after 2022-01-01\n",
    "#df = df[df['date'] < '2021-01-01']\n",
    "shape_values_df_ensemble = pd.DataFrame()\n",
    "df_result = pd.DataFrame()\n",
    "date = \"2022-01-01\"  # Define the 'date' variable\n",
    "train_start_date = \"2019-01-01\"\n",
    "cutoff_date = \"2023-01-01\"\n",
    "#order unique_dates\n",
    "y_pred_test=pd.DataFrame()\n",
    "\n",
    "for i in range(2, 6):\n",
    "    train_df = df[(df['date'] >= train_start_date) & (df['date'] < date)]\n",
    "    test_df = df[(df['date'] < cutoff_date) & (df['date'] >= date)]\n",
    "    train_df = train_df.drop(['date','area_id'], axis=1)\n",
    "    test_df = test_df.drop(['date','area_id'], axis=1)\n",
    "    train_df_new = train_df.drop(['phase{}_worse'.format(j) for j in range(2, 6) if j != i], axis=1)\n",
    "    test_df_new = test_df.drop(['phase{}_worse'.format(j) for j in range(2, 6) if j != i], axis=1)\n",
    "# drop rows with NaN in phase{}_percent\n",
    "    train_df_new = train_df_new.dropna(subset=['phase{}_worse'.format(i)])\n",
    "    test_df_new = test_df_new.dropna(subset=['phase{}_worse'.format(i)])\n",
    "    test_index = test_df_new.index\n",
    "    # Split into features and target\n",
    "    X_train = train_df_new.drop('phase{}_worse'.format(i), axis=1)\n",
    "    y_train = train_df_new['phase{}_worse'.format(i)]\n",
    "    X_test = test_df_new.drop('phase{}_worse'.format(i), axis=1)\n",
    "    y_test = test_df_new['phase{}_worse'.format(i)]\n",
    "    #fews_ipc_ha_test = X_test['fews_ipc_ha']\n",
    "    #X_train = X_train.drop(['fews_ipc_ha'], axis=1)\n",
    "    #X_test = X_test.drop(['fews_ipc_ha'], axis=1)\n",
    "    if i == 3:\n",
    "        best_params_xgb_regressor = best_params_xgb_regressor_for_p3\n",
    "    model = xgb.XGBRegressor(**best_params_xgb_regressor)\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    # for y_pred_test, add a column to indicate the phase\n",
    "    #y_pred_test = pd.concat([y_pred_test, pd.DataFrame({'y_pred': y_pred, 'y_test': y_test, 'phase': [i]*len(y_pred),'fews_ipc_ha':fews_ipc_ha_test,'test_index':test_index})], ignore_index=True)\n",
    "    if i != 5:\n",
    "        y_pred_test = pd.concat([y_pred_test, pd.DataFrame({'y_pred': y_pred, 'y_test': y_test, 'phase': [i]*len(y_pred)})], ignore_index=True)\n",
    "    else:\n",
    "        y_pred_test = pd.concat([y_pred_test, pd.DataFrame({'y_pred': y_pred, 'y_test': y_test, 'phase': [i]*len(y_pred),'test_index':test_index})], ignore_index=True)\n",
    "    # shap values\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    \n",
    "    #save shap values\n",
    "    shap_values_df = pd.DataFrame(shap_values, columns=X_train.columns)\n",
    "    \n",
    "    # add a column to indicate the phase\n",
    "    shap_values_df['phase'] = i\n",
    "    \n",
    "    # append to shape_values_df_ensemble\n",
    "    shape_values_df_ensemble = pd.concat([shape_values_df_ensemble, shap_values_df], ignore_index=True)\n",
    "y_pred_test = convert_prob_to_phase(y_pred_test)\n",
    "y_test = y_pred_test['overall_phase']\n",
    "y_pred = y_pred_test['overall_phase_pred']\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "accuracy_score_new, sensitivity, precision, overall_r2 = all_metrics(y_test, y_pred, cm, y_pred_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score_new)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Overall R²(Phase 3 or more):\", overall_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swl00\\AppData\\Local\\Temp\\ipykernel_31420\\2700769420.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extracted['test_index'] = df_extracted.index\n"
     ]
    }
   ],
   "source": [
    "# remove column if it is all 0\n",
    "y_pred_test = y_pred_test.loc[:, (y_pred_test != 0).any(axis=0)]\n",
    "#extract df area_id, date\n",
    "df_extracted = df[['area_id', 'date']]\n",
    "\n",
    "# generate index\n",
    "df_extracted['test_index'] = df_extracted.index\n",
    "\n",
    "# merge y_pred_test with df_extracted on test_index\n",
    "y_pred_test = y_pred_test.merge(df_extracted, on='test_index', how='left')\n",
    "#read IPCCH\n",
    "PATH = r'C:\\Users\\swl00\\IFPRI Dropbox\\Weilun Shi\\Google fund\\Analysis\\1.Source Data\\IPCCH_2017_2025_final_v12102025_with_zscores.csv'\n",
    "df_ipcch = pd.read_csv(PATH)\n",
    "# keep only admin_code, lat, lon\n",
    "df_ipcch = df_ipcch[['admin_code', 'lat', 'lon']]\n",
    "\n",
    "# rename admin_code to area_id\n",
    "df_ipcch = df_ipcch.rename(columns={'admin_code': 'area_id'})\n",
    "\n",
    "# merge y_pred_test with df_ipcch on area_id\n",
    "y_pred_test = y_pred_test.merge(df_ipcch, on='area_id', how='left')\n",
    "# save y_pred_test to csv\n",
    "y_pred_test.to_csv(r'C:\\Users\\swl00\\IFPRI Dropbox\\Weilun Shi\\Google fund\\Analysis\\2.source_code\\Step5_Geo_RF_trial\\IPCCH_model\\forecasting_prediction\\forecasting_y_pred_test_2022.csv', index=False)\n",
    "# clean all memory\n",
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
